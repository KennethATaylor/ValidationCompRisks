---
title: "External validation of the performance of competing risks prediction models: a guide through modern methods -  Cause specific hazard models"
always_allow_html: true
output:
  github_document:
    toc: true
    toc_depth: 4
  keep_text: true
  pandoc_args: --webtex
---
  
## Steps
  
The steps taken in this file are:   
1. To develop a competing risks prediction model cause specific hazards approach;  
2. To assess the performance of the model in terms of calibration, discrimination and overall prediction error;  
3. To assess the potential clinical utility the model using decision curve analysis;

### Installing and loading packages and import data

The following libraries are needed to achieve the outlined goals, the code chunk below will a) check whether you already have them installed, b) install them for you if not already present, and c) load the packages into the session.


```{r setup, include=FALSE}
# Knitr options
knitr::opts_chunk$set(
  fig.retina = 3,
  fig.path = "imgs/Prediction_CSC/"
)
```

```{r, wdlib, message=FALSE,warning=FALSE}
# Use pacman to check whether packages are installed, if not load
if (!require("pacman")) install.packages("pacman")
library(pacman)

pacman::p_load(
  rio,
  survival,
  rms,
  mstate,
  sqldf,
  pec,
  riskRegression,
  survAUC,
  survivalROC,
  timeROC,
  plotrix,
  splines,
  knitr,
  table1,
  kableExtra,
  gtsummary,
  boot,
  tidyverse,
  rsample,
  gridExtra,
  webshot
)

rdata <- readRDS(here::here("Data/rdata.rds"))
vdata <- readRDS(here::here("Data/vdata.rds"))

rdata$hr_status <- relevel(rdata$hr_status, ref = "ER and/or PR +")
vdata$hr_status <- relevel(vdata$hr_status, ref = "ER and/or PR +")
```

We loaded the development data (rdata) and the validation data (vdata).
More details about development and validation data are provided in the manuscript.


### Descriptive statistics

```{r, import,echo=FALSE}
rsel <- rdata[, c("id", "age", "size", "ncat", "hr_status")]
vsel <- vdata[, c("id", "age", "size", "ncat", "hr_status")]
rsel$dt <- 1
vsel$dt <- 2
cdata <- rbind(rsel, vsel)
cdata$dt <- factor(cdata$dt,
                   levels = c(1, 2),
                   labels = c("Development data", "Validation data")
)
label(cdata$age) <- "Age"
label(cdata$size) <- "Size"
label(cdata$ncat) <- "Nodal status"
label(cdata$hr_status) <- "Hormon receptor status"
# Units
units(cdata$age) <- "years"
units(cdata$size) <- "cm"
options(prType = "html")
tab1 <- table1(
  ~ age + size + ncat + hr_status | dt, data = cdata, 
  overall = FALSE, 
  topclass = "Rtable1-zebra", 
)
```

```{r tab1_bis, echo=FALSE}
gtsummary::tbl_summary(
  data = cdata %>% select(-id),
  label = list(age ~ "Age (years)", size ~ "Size (cm)"),
  by = "dt", 
  type = all_continuous() ~ "continuous2",
  statistic = all_continuous() ~ c(
    "{mean} ({sd})",
    "{median} ({min}, {max})"
  ),
) %>% 
  gtsummary::as_kable_extra() %>% 
  kableExtra::kable_styling("striped") 
```

## Goal 1 - develop a competing risks prediction model


### 1.1 Cumulative incidence curves
First, we draw the cumulative incidence curves of breast cancer recurrence.

```{r, cuminc, fig.align='center'}
# Expand datasets
# Create indicator variables for the outcome
rdata$status_num <- as.numeric(rdata$status) - 1
rdata$status1[rdata$status_num == 1] <- 1
rdata$status1[rdata$status_num != 1] <- 0
rdata$status2[rdata$status_num == 2] <- 2
rdata$status2[rdata$status_num != 2] <- 0
# Create indicator variables for the outcome
vdata$status_num <- as.numeric(vdata$status) - 1
vdata$status1[vdata$status_num == 1] <- 1
vdata$status1[vdata$status_num != 1] <- 0
vdata$status2[vdata$status_num == 2] <- 2
vdata$status2[vdata$status_num != 2] <- 0

# Expand data to prepare for fitting the model 
rdata.w <- crprep(
  Tstop = "time",
  status = "status_num",
  trans = c(1, 2),
  id = "id",
  keep = c("age", "size", "ncat", "hr_status"),
  data = rdata
)
# Save extended data with weights for recurrence (failcode=1)
# and non recurrence mortality (failcode=2)
rdata.w1 <- rdata.w %>% filter(failcode == 1)
rdata.w2 <- rdata.w %>% filter(failcode == 2)
vdata.w <- crprep(
  Tstop = "time",
  status = "status_num",
  trans = c(1, 2),
  id = "id",
  keep = c("age", "size", "ncat", "hr_status"),
  data = vdata
)
vdata.w1 <- vdata.w %>% filter(failcode == 1)
vdata.w2 <- vdata.w %>% filter(failcode == 2)
# Development set
mfit3 <- survfit(
  Surv(Tstart, Tstop, status == 1) ~ 1,
  data = rdata.w1, weights = weight.cens
)
mfit4 <- survfit(
  Surv(Tstart, Tstop, status == 1) ~ 1,
  data = vdata.w1, weights = weight.cens
)
par(xaxs = "i", yaxs = "i", las = 1)
oldpar <- par(mfrow = c(1, 2), mar = c(5, 5, 1, 1))
plot(mfit3,
     col = 1, lwd = 2,
     xlab = "Years since BC diagnosis",
     ylab = "Cumulative incidence", bty = "n",
     ylim = c(0, 0.25), xlim = c(0, 5), fun = "event", conf.int = TRUE
)
title("Development data")
plot(mfit4,
     col = 1, lwd = 2,
     xlab = "Years since BC diagnosis",
     ylab = "Cumulative incidence", bty = "n",
     ylim = c(0, 0.25), xlim = c(0, 5), fun = "event", conf.int = TRUE
)
title("Validation data")
par(oldpar)
# Cumulative incidences
smfit3 <- summary(mfit3, times = c(1, 2, 3, 4, 5))
smfit4 <- summary(mfit4, times = c(1, 2, 3, 4, 5))
```

```{r, res_ci, fig.align='center',echo=FALSE}
res_ci <- cbind(
  1 - smfit3$surv,
  1 - smfit3$upper,
  1 - smfit3$lower,
  1 - smfit4$surv,
  1 - smfit4$upper,
  1 - smfit4$lower
)
res_ci <- round(res_ci, 2)
rownames(res_ci) <- c(
  "1-year", "2-year",
  "3-year", "4-year",
  "5-year"
)
colnames(res_ci) <- rep(c(
  "Estimate", "Lower .95",
  "Upper .95"
), 2)
kable(res_ci,
      row.names = TRUE
) %>%
  kable_styling("striped", position = "center") %>%
  add_header_above(c(" " = 1, "Development data" = 3, "Validation data" = 3))
```

The 5-year cumulative incidence of breast cancer recurrence was 14% (95% CI: 11-16%), and 10% (95%CI: 8-12%)

### 1.2 Check non-linearity of continuous predictors

Here we investigate the potential non-linear relation between continuous predictors (i.e. age and size) and the outcomes. We apply three-knot restricted cubic splines using `rms::rcs()` function (details are given in e.g. Frank Harrell's book 'Regression Model Strategies (second edition)', page 27.

```{r,ff, warning=FALSE, fig.align='center'}
# Models without splines
fit_csh <- CSC(Hist(time, status_num) ~ age + size +
  ncat + hr_status, data = rdata, fitter = "cph")
fit_csc1 <- fit_csh$models$`Cause 1`
fit_csc2 <- fit_csh$models$`Cause 2`
# Models with splines
dd <- datadist(rdata)
options(datadist = "dd")
# Recurrence
fit_csc1_rcs <- cph(Surv(time, status_num == 1) ~ rcs(age, 3) + rcs(size, 3) +
  ncat + hr_status, x = T, y = T, surv = T, data = rdata)
# print(fit_csc1_rcs)
# print(summary(fit_csc1_rcs))
# print(anova(fit_csc1_rcs))
P_csc1_age_rcs <- Predict(fit_csc1_rcs, "age")
P_csc1_size_rcs <- Predict(fit_csc1_rcs, "size")
options(datadist = NULL)
# Non-recurrence mortality
dd <- datadist(rdata)
options(datadist = "dd")
fit_csc2_rcs <- cph(Surv(time, status_num == 2) ~ rcs(age, 3) + rcs(size, 3) +
  ncat + hr_status, x = T, y = T, surv = T, data = rdata)
# print(fit_csc2_rcs)
# print(summary(fit_csc2_rcs))
# print(anova(fit_csc2_rcs))
P_csc2_age_rcs <- Predict(fit_csc2_rcs, "age")
P_csc2_size_rcs <- Predict(fit_csc2_rcs, "size")
options(datadist = NULL)
oldpar <- par(mfrow = c(2, 2), mar = c(5, 5, 1, 1))
par(xaxs = "i", yaxs = "i", las = 1)
plot(P_csc1_age_rcs$age, P_csc1_age_rcs$yhat,
  type = "l", lwd = 2, col = "blue", bty = "n",
  xlab = "Age at breast cancer diagnosis", ylab = "log Relative Hazard", ylim = c(-2, 2),
  xlim = c(65, 95)
)
polygon(c(P_csc1_age_rcs$age, rev(P_csc1_age_rcs$age)),
  c(P_csc1_age_rcs$lower, rev(P_csc1_age_rcs$upper)),
  col = "grey75",
  border = FALSE
)
par(new = TRUE)
plot(P_csc1_age_rcs$age, P_csc1_age_rcs$yhat,
  type = "l", lwd = 2, col = "blue", bty = "n",
  xlab = "Age at breast cancer diagnosis", ylab = "log Relative Hazard",
  ylim = c(-2, 2), xlim = c(65, 95)
)
title("Recurrence")
# CSC 1- size
par(xaxs = "i", yaxs = "i", las = 1)
plot(P_csc1_size_rcs$size, P_csc1_size_rcs$yhat,
  type = "l", lwd = 2, col = "blue", bty = "n",
  xlab = "Size of breast cancer", ylab = "log Relative Hazard", ylim = c(-2, 2),
  xlim = c(0, 7)
)
polygon(c(P_csc1_size_rcs$size, rev(P_csc1_size_rcs$size)),
  c(P_csc1_size_rcs$lower, rev(P_csc1_size_rcs$upper)),
  col = "grey75",
  border = FALSE
)
par(new = TRUE)
plot(P_csc1_size_rcs$size, P_csc1_size_rcs$yhat,
  type = "l", lwd = 2, col = "blue", bty = "n",
  xlab = "Size of breast cancer", ylab = "log Relative Hazard",
  ylim = c(-2, 2), xlim = c(0, 7)
)
title("Recurrence")
par(xaxs = "i", yaxs = "i", las = 1)
options(datadist = NULL)
# CSC 2- age
plot(P_csc2_age_rcs$age, P_csc2_age_rcs$yhat,
  type = "l", lwd = 2, col = "blue", bty = "n",
  xlab = "Age at breast cancer diagnosis", ylab = "log Relative Hazard", ylim = c(-2, 2),
  xlim = c(65, 95)
)
polygon(c(P_csc2_age_rcs$age, rev(P_csc2_age_rcs$age)),
  c(P_csc2_age_rcs$lower, rev(P_csc2_age_rcs$upper)),
  col = "grey75",
  border = FALSE
)
par(new = TRUE)
plot(P_csc2_age_rcs$age, P_csc2_age_rcs$yhat,
  type = "l", lwd = 2, col = "blue", bty = "n",
  xlab = "Age at breast cancer diagnosis", ylab = "log Relative Hazard",
  ylim = c(-2, 2), xlim = c(65, 95)
)
title("Non recurrence mortality")
# CSC 2 - size
par(xaxs = "i", yaxs = "i", las = 1)
plot(P_csc2_size_rcs$size, P_csc2_size_rcs$yhat,
  type = "l", lwd = 2, col = "blue", bty = "n",
  xlab = "Size of breast cancer", ylab = "log Relative Hazard", ylim = c(-2, 2),
  xlim = c(0, 7)
)
polygon(c(P_csc2_size_rcs$size, rev(P_csc2_size_rcs$size)),
  c(P_csc2_size_rcs$lower, rev(P_csc2_size_rcs$upper)),
  col = "grey75",
  border = FALSE
)
par(new = TRUE)
plot(P_csc2_size_rcs$size, P_csc2_size_rcs$yhat,
  type = "l", lwd = 2, col = "blue", bty = "n",
  xlab = "Size of breast cancer", ylab = "log Relative Hazard",
  ylim = c(-2, 2), xlim = c(0, 7)
)
title("Non recurrence mortality")
options(datadist = NULL)
par(oldpar)
```

```{r, res_aic, fig.align='center',echo=FALSE}
res_AIC <- matrix(c(
  AIC(fit_csc1), AIC(fit_csc1_rcs),
  AIC(fit_csc2), AIC(fit_csc2_rcs)
),
byrow = T, ncol = 2, nrow = 2,
dimnames = list(
  c(
    "Recurrence specific hazard",
    "Non recurrence mortality"
  ),
  c(
    "AIC without splines",
    "AIC with splines"
  )
)
)
kable(res_AIC,
  row.names = TRUE
) %>%
  kable_styling("striped", position = "center")
```

Both the graphical comparison and the AIC comparison suggested no relevant departure from linear relations between the continuous predictors (age and size) and the cause-specific hazards (recurrence and non-recurrence mortality).  

### 1.3 Checking proportional hazards assumption

We now examine the fits further by checking the proportionality of the cause-specific hazards of the models.

```{r,ph_csc1, message=FALSE, warning=FALSE,fig.align='center'}
zp_csc1 <- cox.zph(fit_csc1, transform = "identity")
par(las = 1, xaxs = "i", yaxs = "i")
# c(bottom, left, top, right)
oldpar <- par(mfrow = c(2, 2), mar = c(5, 6.1, 3.1, 1))
sub_title <- c("Age", "Size", "Lymph node status", "HR status")
for (i in 1:4) {
  plot(zp_csc1[i], resid = F, bty = "n", xlim = c(0, 5))
  abline(0, 0, lty = 3)
  title(sub_title[i])
}
mtext("Recurrence", side = 3, line = -1, outer = TRUE, font = 2)
par(oldpar)
kable(round(zp_csc1$table, 3)) %>%
  kable_styling("striped", position = "center")
```


```{r,ph_csc2, message=FALSE, warning=FALSE,fig.align='center'}
zp_csc2 <- cox.zph(fit_csc2, transform = "identity")
par(las = 1, xaxs = "i", yaxs = "i")
# c(bottom, left, top, right)
oldpar <- par(mfrow = c(2, 2), mar = c(5, 6.1, 3.1, 1))
sub_title <- c("Age", "Size", "Lymph node status", "HR status")
for (i in 1:4) {
  plot(zp_csc2[i], resid = F, bty = "n", xlim = c(0, 5))
  abline(0, 0, lty = 3)
  title(sub_title[i])
}
mtext("Non-recurrence mortality", side = 3, line = -1, outer = TRUE, font = 2)
par(oldpar)
kable(round(zp_csc2$table, 3)) %>%
  kable_styling("striped", position = "center")
```

The statistical tests showed a potential violation of the proportional hazards assumption for nodal status in the model for non-recurrence mortality. For simplicity we ignore this violation in the remainder.

### 1.4 Examine the risk fit of the models

We show the results of the Cox proportional cause-specific hazards regression models

+ Cox proportional hazard model for recurrence

```{r, summary_csc1, fig.align='center',warning=FALSE}
dd <- datadist(rdata)
options(datadist = "dd")
options(prType = "html")
fit_csc1_cph <- cph(Surv(time, status_num == 1) ~ age + size +
  ncat + hr_status,
x = T, y = T, surv = T, data = rdata
)
print(fit_csc1_cph)
# print(summary(fit_csc1_cph))
options(datadist = NULL)
```

+ Cox proportional non recurrence mortality-specific hazard model

```{r, summary_csc2, fig.align='center',warning=FALSE}
dd <- datadist(rdata)
options(datadist = "dd")
options(prType = "html")
fit_csc2_cph <- cph(Surv(time, status_num == 2) ~ age + size +
  ncat + hr_status,
x = T, y = T, surv = T, data = rdata
)
print(fit_csc2_cph)
# print(summary(fit_csc2_cph))
options(datadist = NULL)
```

The coefficients of the models indicated that larger tumor size, positive nodal status and negative hormone receptor status status were associated with higher risk to develop a breast cancer recurrence, while older patients and larger tumors are associated with higher risk of non recurrence mortality.

## Goal 2 - Assessing performance of a competing risks prediction model

Here we evaluate the performance of the risk prediction models in terms of calibration, discrimination and overall prediction error. 

### 2.1 Overall prediction error

We calculate the Brier Score, and the scaled Brier scale and the corresponding confidence intervals..

Some confidence intervals are calculated using the bootstrap percentile method.
```{r, bootstrap,warning=FALSE}
# Bootstrapping data
set.seed(20201214)
rboot <- bootstraps(rdata, times = 10)
vboot <- bootstraps(vdata, times = 10)
# NOTE: B=10 to speed up the procedure, is typically set to 100 or 1000
```

```{r, overall, warning=FALSE}
# riskRegression::Score() to calculate Brier and scaled Brier (in this function called "ipa")
# Development set - apparent validation
score_rdata1 <- Score(list("CSH development" = fit_csh),
  formula = Hist(time, status_num) ~ 1,
  data = rdata, conf.int = TRUE, times = 4.99,
  cens.model = "km", metrics = "brier",
  summary = "ipa", cause = 1
)
# Validation set - external validation
score_vdata1 <-
  Score(list("CSH validation" = fit_csh),
    formula = Hist(time, status_num) ~ 1,
    data = vdata, conf.int = TRUE, times = 4.99,
    cens.model = "km", metrics = "brier",
    summary = "ipa", cause = 1
  )
# Development set - internal validation (bootstrap)
# mstate::crprep() for every bootstrap sample
crprep_boot <- function(split) {
  crprep(
    Tstop = "time", status = "status_num",
    trans = 1, data = analysis(split),
    keep = c(
      "status_num", "age", "size",
      "ncat", "hr_status"
    )
  )
}
# riskRegression::Score() to calculate Brier and scaled Brier (here called IPA) for every bootstrap sample
score_boot_1 <- function(split) {
  Score(list("CSH" = fit_csh),
    formula = Hist(time, status_num) ~ 1,
    data = analysis(split), conf.int = FALSE, times = 4.99,
    cens.model = "km", metrics = "brier", cause = 1,
    summary = "ipa"
  )$Brier[[1]]$IPA[2]
}
# Development data
rboot <- rboot %>% mutate(
  cr.prep = map(splits, crprep_boot),
  IPA1 = map_dbl(splits, score_boot_1)
)
# Validation data
vboot <- vboot %>% mutate(
  cr.prep = map(splits, crprep_boot),
  IPA1 = map_dbl(splits, score_boot_1),
)
```

```{r, res_ov, fig.align='center',echo=FALSE}
# Table overall measures
alpha <- .05
k <- 2 # number of digits
res_ov_csh <- matrix(unlist(c(
  score_rdata1$Brier$score$Brier[2],
  # Brier apparent validation
  score_rdata1$Brier$score[2, 6],
  score_rdata1$Brier$score[2, 7],
  score_vdata1$Brier$score$Brier[2],
  # Brier external validation
  score_vdata1$Brier$score[2, 6],
  score_vdata1$Brier$score[2, 7],
  score_rdata1$Brier$score$IPA[2],
  # IPA apparent validation
  quantile(rboot$IPA1, probs = alpha / 2),
  quantile(rboot$IPA1, probs = 1 - alpha / 2),
  score_vdata1$Brier$score$IPA[2],
  # IPA external validation
  quantile(vboot$IPA1, probs = alpha / 2),
  quantile(vboot$IPA1, probs = 1 - alpha / 2)
)),
nrow = 2, ncol = 6,
byrow = T,
dimnames =
  list(
    c("Brier", "scaled Brier"),
    rep(c("Estimate", "Lower .95 ", "Upper .95"), 2)
  )
)
res_ov <- round(res_ov_csh, 2) # Digits
kable(res_ov) %>%
  kable_styling("striped", position = "center") %>%
  add_header_above(c(
    " " = 1,
    "Development data" = 3,
    "Validation data" = 3
  ))
```

Note: unexpectedly, the point estimate for the Brier score is lower (thus better) and for the scaled Brier score is higher (thus better) in the validation data compared to the development data.

### 2.2 Discrimination

We here calculate

+ The 5-year C-index. More details are in the main manuscript and its references;
+ The 5-year time-dependent AUC. More details are in the manuscript and in its references;  

We used the time horizon up to 4.99 and not 5 years since controls are considered patients at risk after the time horizon.

```{r, discrimination,warning=FALSE,message=FALSE}
# C-index
# Development set (Apparent validation)
C_rdata1_cph1 <- unlist(pec::cindex(fit_csh,
                                    cause = 1,
                                    eval.times = 4.99
)$AppCindex)
# Validdation set
C_vdata1_cph1 <- unlist(pec::cindex(fit_csh,
                                    data = vdata,
                                    cause = 1, eval.times = 4.99
)$AppCindex)

# 5-year time dependent AUC
# Development set (Apparent validation)
Uno_rdata1_CSC <-
  timeROC(
    T = rdata$time, delta = rdata$status1,
    marker = predictRisk(fit_csh, newdata = rdata, cause = 1, times = 5),
    cause = 1, weighting = "marginal", times = 4.99,
    iid = TRUE
  )
# Validdation set
Uno_vdata1_CSC <-
  timeROC(
    T = vdata$time, delta = vdata$status1,
    marker = predictRisk(fit_csh, newdata = vdata, cause = 1, times = 5),
    cause = 1, weighting = "marginal", times = 4.99,
    iid = TRUE
  )

# NOTE: if you have many observations (n > 2000), standard error computation may be really long.
# In that case, you may consider using bootstrapping to calculate confidence intervals.
# NOTE: AUC_1: controls = subjects free of any event 
# NOTE: AUC_2: controls = subjects does not experience the primary event, this is what we use here 

# Bootstraping Wolbers' C-index to calculate the bootstrap percentile confidence intervals
C_boot1_cph1 <- function(split) {
  unlist(pec::cindex(fit_csh,
                     data = analysis(split),
                     cause = 1, eval.times = 4.99
  )$AppCindex)
}
C_boot1_cph2 <- function(split) {
  unlist(pec::cindex(fit_csh,
                     data = analysis(split),
                     cause = 2, eval.times = 4.99
  )$AppCindex)
}
# Run time-dependent AUC in the bootstrapped development and validation data
# to calculate the non-parametric CI through percentile bootstrap
rboot <- rboot %>% mutate(
  C1 = map_dbl(splits, C_boot1_cph1),
  C2 = map_dbl(splits, C_boot1_cph2)
)
vboot <- vboot %>% mutate(
  C1 = map_dbl(splits, C_boot1_cph1),
  C2 = map_dbl(splits, C_boot1_cph2)
)
```

```{r, res_disc, fig.align='center',echo=FALSE}
alpha <- .05
k <- 2
res_discr_csh <- matrix(c(
  ## C-index
  # Development CSH1
  C_rdata1_cph1,
  quantile(rboot$C1, probs = alpha / 2),
  quantile(rboot$C1, probs = 1 - alpha / 2),
  # Validation CSH1
  C_vdata1_cph1,
  quantile(vboot$C1, probs = alpha / 2),
  quantile(vboot$C1, probs = 1 - alpha / 2),
  ## time-dependent AUC
  # Development CSH1
  Uno_rdata1_CSC$AUC["t=4.99"],
  Uno_rdata1_CSC$AUC["t=4.99"] -
    qnorm(1 - alpha / 2) * Uno_rdata1_CSC$inference$vect_sd_1["t=4.99"],
  Uno_rdata1_CSC$AUC["t=4.99"] +
    qnorm(1 - alpha / 2) * Uno_rdata1_CSC$inference$vect_sd_1["t=4.99"],
  # Validation CSH1
  Uno_vdata1_CSC$AUC["t=4.99"],
  Uno_vdata1_CSC$AUC["t=4.99"] -
    qnorm(1 - alpha / 2) * Uno_vdata1_CSC$inference$vect_sd_1["t=4.99"],
  Uno_vdata1_CSC$AUC["t=4.99"] +
    qnorm(1 - alpha / 2) * Uno_vdata1_CSC$inference$vect_sd_1["t=4.99"]
),
nrow = 2, ncol = 6, byrow = T,
dimnames = list(
  c("Wolbers C", "Uno AUC"),
  rep(c("Estimate", "Lower .95 ", "Upper .95"), 2)
)
)
res_discr_csh <- round(res_discr_csh, k)
kable(res_discr_csh) %>%
  kable_styling("striped", position = "center") %>%
  add_header_above(c(
    " " = 1, "Development data" = 3,
    "Validation data" = 3
  ))
```

The time-dependent AUC at 5 years was 0.74 in the validation set.

### 2.3 Calibration

We assess calibration by:
  
+ The calibration plot as a graphical representation of calibration;  

+ The observed vs expected ratio (O/E ratio);  

+ The squared bias, i.e., the average squared difference between actual risks and risk predictions;

+ The integrated Calibration Index (ICI), i.e., the average absolute difference between actual risks and risk predictions;  

+ E50, E90 and Emax denote the median, 90th percentile and the maximum of the absolute differences between actual risks and risk predictions;  


#### 2.3.1 Numerical summaries of calibration

We calculate the O/E ratio, squared bias, ICI, E50, E90 and Emax at 5 years in the development and validation data.

```{r, OE, fig.align='center',warning=FALSE,message=FALSE}
# Load the function to calculate the OE ratio
source(here::here("R/OE_function.R"))
# O = estimated cumulative incidence at 5 years
# E = mean of the predicted cumulative incidence at 5 years
Po_t <- summary(
  survfit(Surv(Tstart, Tstop, status == 1) ~ 1,
          data = vdata.w1, weights = weight.cens
  ),
  times = 5
)
obs_vdata <- 1 - Po_t$surv
obs_stderror <- Po_t$std.err
# Observed/Expected ratio
OE_vdata <- OE_function(
  fit = fit_csh, newdata = vdata, cause = 1,
  thorizon = 5, obs_cif = obs_vdata,
  std.error = obs_stderror
)
res_OE <- matrix(OE_vdata,
                 ncol = 3, nrow = 1, byrow = T,
                 dimnames = list(
                   c("O/E ratio"),
                   c("Estimate", "Lower.95", "Upper.95")
                 )
)
kable(res_OE) %>%
  kable_styling("striped", position = "center")
```

The competing risks prediction model slightly overestimates the absolute risk to develop breast cancer recurrence in the validation data.

```{r, calmeasures, fig.align='center',warning=FALSE,message=FALSE}
# Calibration measures: squared bias, ICI, E50, E90, Emax
source(here::here("R/cal_measures.R"))
calmeas_vdata <- cal_measures(vdata, 5, fit_csh,
                              Tstop = "time", status = "status_num", cause = 1
)
# Squared bias
avg_sqbias_CSC <- mean((predictRisk(fit_csh, newdata = vdata, cause = 1, times = 5)
                        - obs_vdata)**2)
res_calmeas <- matrix(c(avg_sqbias_CSC, calmeas_vdata),
                      ncol = 1, nrow = 5, byrow = T,
                      dimnames = list(
                        c("Average squared bias", "ICI", "E50", "E90", "Emax"),
                        c("Estimate")
                      )
)
res_calmeas <- round(res_calmeas, 2)
kable(res_calmeas) %>%
  kable_styling("striped", position = "center")
```

#### 2.3.2 Calibration plot 
Calibration plot for the validation data is calculated using pseudo-values.

Calibration plots reports:  
  
+ on the _x-axis_ the estimated risk by the prediction model by a fixed time point (e.g. at 5 years);
+ on the _y-axis_ the estimated actual risk by a fixed time point (e.g. at 5 years);
+ The 45-degree line indicates perfect calibration. 
Points below the 45-degree line indicate that the model overestimates the estimated actual risk. 
If points are above the 45-degree line, the model underestimates the estimated actual risk.

```{r, cal_rcs, fig.align='center',warning=FALSE,message=FALSE}
x <- Score(list(model1 = fit_csh), Hist(time, status_num) ~ 1,
           data = vdata,
           cause = 1, times = 5, plots = "cal"
)
oldpar <- par(
  mar = c(5.1, 5.8, 4.1, 2.1), mgp = c(4.25, 1, 0),
  xaxs = "i", yaxs = "i", las = 1
)
plotCalibration(x,
                brier.in.legend = FALSE,
                auc.in.legend = FALSE, cens.method = "pseudo",
                cex = 1, xlim = c(0, 0.5), ylim = c(0, 0.5), rug=TRUE
)
title("Cause-specific hazards models")
par(oldpar)
```

Calibration plot suggests that the prediction model seems to overestimate the actual risk, especially at the lower and higher values of the estimated risk.


## Goal 3 -  Clinical utility

Clinical utility can be measured by the net benefit and plotted in a decision curve. Details about net benefit, decision curve calculation and interpretation are provided in the manuscript (see also the appendix) and its references.

```{r, dca, message=FALSE,warning=FALSE, fig.align='center'}
# Run the stdca function to calculate the net benefit and the elements needed to develop decision curve analysis
source(here::here("R/stdca.R"))
# Development data
# calculation estimated risk
rdata$pred5 <- predictRisk(fit_csh, newdata = rdata, times = 5)
rdata <- as.data.frame(rdata)
dca_rdata_1 <- stdca(
  data = rdata, outcome = "status_num", ttoutcome = "time",
  timepoint = 5, predictors = "pred5", xstop = 0.35,
  ymin = -0.01, graph = FALSE, cmprsk = TRUE
)
# Decision curves plot
oldpar <- par(xaxs = "i", yaxs = "i", las = 1, mar = c(6.1, 5.8, 4.1, 2.1), mgp = c(4.25, 1, 0))
plot(dca_rdata_1$net.benefit$threshold,
     dca_rdata_1$net.benefit$pred5,
     type = "l", lwd = 2, lty = 1,
     xlab = "", ylab = "Net Benefit",
     xlim = c(0, 0.5), ylim = c(-0.10, 0.10), bty = "n", xaxt = "n"
)
legend("topright", c("Treat all", "Treat none", "Prediction model"),
       lwd = c(2, 2, 2), lty = c(1, 2, 1), col = c("darkgray", "black", "black"), bty = "n"
)
lines(dca_rdata_1$net.benefit$threshold, dca_rdata_1$net.benefit$none,
      type = "l", lwd = 2, lty = 4
)
lines(dca_rdata_1$net.benefit$threshold, dca_rdata_1$net.benefit$all,
      type = "l", lwd = 2, col = "darkgray"
)
axis(1, at = c(0, 0.1, 0.2, 0.3, 0.4, 0.5))
axis(1,
     pos = -0.145, at = c(0.1, 0.2, 0.3, 0.4, 0.5),
     labels = c("1:9", "1:4", "3:7", "2:3", "1:1")
)
mtext("Threshold probability", 1, line = 2)
mtext("Harm to benefit ratio", 1, line = 5)
title("Development data")
par(oldpar)
# Validation data
# Predicted probability calculation
vdata$pred5 <- predictRisk(fit_csh, newdata = vdata, times = 5)
vdata <- as.data.frame(vdata)
# Run decision curve analysis
# Development data
# Model without PGR
dca_vdata_1 <- stdca(
  data = vdata, outcome = "status_num", ttoutcome = "time",
  timepoint = 5, predictors = "pred5", xstop = 0.45,
  ymin = -0.01, graph = FALSE, cmprsk = TRUE
)
# Decision curves plot
oldpar <- par(xaxs = "i", yaxs = "i", las = 1, mar = c(6.1, 5.8, 4.1, 2.1), mgp = c(4.25, 1, 0))
plot(dca_vdata_1$net.benefit$threshold,
     dca_vdata_1$net.benefit$pred5,
     type = "l", lwd = 2, lty = 1,
     xlab = "", ylab = "Net Benefit",
     xlim = c(0, 0.5), ylim = c(-0.10, 0.10), bty = "n", xaxt = "n"
)
lines(dca_vdata_1$net.benefit$threshold,
      dca_vdata_1$net.benefit$none,
      type = "l", lwd = 2, lty = 4
)
lines(dca_vdata_1$net.benefit$threshold,
      dca_vdata_1$net.benefit$all,
      type = "l", lwd = 2, col = "darkgray"
)
legend("topright", c("Treat all", "Treat none", "Prediction model"),
       lwd = c(2, 2, 2), lty = c(1, 2, 1), col = c("darkgray", "black", "black"), bty = "n"
)
axis(1, at = c(0, 0.1, 0.2, 0.3, 0.4, 0.5))
axis(1,
     pos = -0.145, at = c(0.1, 0.2, 0.3, 0.4, 0.5),
     labels = c("1:9", "1:4", "3:7", "2:3", "1:1")
)
mtext("Threshold probability", 1, line = 2)
mtext("Harm to benefit ratio", 1, line = 5)
title("Validation data")
par(oldpar)
```

If we choose a threshold of 20\%, the model had a net benefit of 0.011 in the development data.  This means that the model would identify 11 patients per 1000 who will have beast cancer recurrence within 5 years since diagnosis where adjuvant chemotherapy is really needed. In the validation data, the model had a net benefit of 0.014 choosing a threshold of 20\%. 

## Additional references

+ Calibration \
https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6152   \
https://onlinelibrary.wiley.com/doi/full/10.1002/sim.8570   \

+ Discrimination  
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4059461 \
https://onlinelibrary.wiley.com/doi/10.1002/sim.5958 \

+ Overall prediction error
https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201000073 \
https://diagnprognres.biomedcentral.com/articles/10.1186/s41512-018-0029-2 \
R Vignette: https://cran.r-project.org/web/packages/riskRegression/vignettes/IPA.html \

+ Clinical utility (decision curves)  
R/SAS/STATA code and references: 
  https://www.mskcc.org/departments/epidemiology-biostatistics/biostatistics/decision-curve-analysis \
More guidelines about net benefit assessment and interpretation \
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6261531/ \
https://diagnprognres.biomedcentral.com/articles/10.1186/s41512-019-0064-7 \

## Reproducibility ticket

```{r repro_ticket, echo=TRUE}
sessionInfo()
```
